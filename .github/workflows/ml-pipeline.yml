name: ML Model CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'Model-Pipeline/**'
      - 'Data-Pipeline/**'
      - 'requirements.txt'
  pull_request:
    branches: [ main ]
  workflow_dispatch:

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  GCP_REGION: us-central1
  MODEL_REGISTRY: ${{ secrets.GCP_ARTIFACT_REGISTRY }}
  PYTHON_VERSION: '3.9'
  MIN_ACCURACY: 0.70
  MIN_F1_SCORE: 0.65
  MAX_BIAS_VIOLATIONS: 5

jobs:
  data-pipeline:
    name: Data Pipeline and Validation
    runs-on: ubuntu-latest
    outputs:
      data-quality: ${{ steps.validation.outputs.passed }}
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          python -c "import pandas, sklearn; print('[OK] Core packages installed')"
      
      - name: Run data generation
        run: |
          cd Data-Pipeline/scripts
          python generate_data.py
      
      - name: Run data preprocessing
        run: |
          cd Data-Pipeline/scripts
          python preprocessing.py
      
      - name: Run data validation
        id: validation
        run: |
          cd Data-Pipeline/scripts
          python validation.py
          
          if [ -f "data/metrics/validation_results.json" ]; then
            PASSED=$(python -c "import json; data=json.load(open('data/metrics/validation_results.json')); print(data['validation_passed'])")
            echo "passed=$PASSED" >> $GITHUB_OUTPUT
            
            if [ "$PASSED" = "False" ]; then
              echo "[ERROR] Data validation failed"
              exit 1
            fi
          fi
      
      - name: Upload data artifacts
        uses: actions/upload-artifact@v3
        with:
          name: processed-data
          path: |
            Data-Pipeline/scripts/data/processed/
            Data-Pipeline/scripts/data/metrics/
          retention-days: 7

  model-training:
    name: Model Training
    runs-on: ubuntu-latest
    needs: data-pipeline
    if: needs.data-pipeline.outputs.data-quality == 'True'
    outputs:
      model-trained: ${{ steps.training.outputs.success }}
      best-model: ${{ steps.training.outputs.model_name }}
      f1-score: ${{ steps.training.outputs.f1_score }}
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Download processed data
        uses: actions/download-artifact@v3
        with:
          name: processed-data
          path: Data-Pipeline/scripts/data/
      
      - name: Train models
        id: training
        run: |
          cd Model-Pipeline
          python run_ml_pipeline.py --quick
          
          if [ -f "results/training_results.json" ]; then
            BEST_MODEL=$(python -c "import json; data=json.load(open('results/training_results.json')); print(data.get('best_model', 'Unknown'))")
            BEST_SCORE=$(python -c "import json; data=json.load(open('results/training_results.json')); print(data.get('best_f1_score', 0))")
            
            echo "success=true" >> $GITHUB_OUTPUT
            echo "model_name=$BEST_MODEL" >> $GITHUB_OUTPUT
            echo "f1_score=$BEST_SCORE" >> $GITHUB_OUTPUT
            echo "[OK] Training: $BEST_MODEL F1=$BEST_SCORE"
          else
            echo "success=false" >> $GITHUB_OUTPUT
            exit 1
          fi
      
      - name: Upload model artifacts
        uses: actions/upload-artifact@v3
        with:
          name: trained-models
          path: |
            Model-Pipeline/models/
            Model-Pipeline/results/
          retention-days: 30

  model-validation:
    name: Model Validation
    runs-on: ubuntu-latest
    needs: model-training
    if: needs.model-training.outputs.model-trained == 'true'
    outputs:
      validation-passed: ${{ steps.validate.outputs.passed }}
      f1-score: ${{ steps.validate.outputs.f1_score }}
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Download artifacts
        uses: actions/download-artifact@v3
        with:
          name: trained-models
          path: Model-Pipeline/
      
      - name: Download data
        uses: actions/download-artifact@v3
        with:
          name: processed-data
          path: Data-Pipeline/scripts/data/
      
      - name: Validate model
        id: validate
        timeout-minutes: 10
        run: |
          cd Model-Pipeline
          timeout 300 python model_validation.py || echo "[WARNING] Validation timeout"
          
          F1_SCORE=${{ needs.model-training.outputs.f1-score }}
          echo "f1_score=$F1_SCORE" >> $GITHUB_OUTPUT
          
          PASS=$(python -c "print($F1_SCORE >= $MIN_F1_SCORE)")
          if [ "$PASS" = "True" ]; then
            echo "passed=true" >> $GITHUB_OUTPUT
            echo "[OK] Validation passed: F1=$F1_SCORE"
          else
            echo "passed=false" >> $GITHUB_OUTPUT
            exit 1
          fi

  bias-detection:
    name: Bias Detection
    runs-on: ubuntu-latest
    needs: model-validation
    if: needs.model-validation.outputs.validation-passed == 'true'
    outputs:
      bias-check-passed: ${{ steps.bias.outputs.passed }}
      violations-count: ${{ steps.bias.outputs.violations }}
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Download artifacts
        uses: actions/download-artifact@v3
        with:
          name: trained-models
          path: Model-Pipeline/
      
      - name: Download data
        uses: actions/download-artifact@v3
        with:
          name: processed-data
          path: Data-Pipeline/scripts/data/
      
      - name: Run bias detection
        id: bias
        timeout-minutes: 10
        run: |
          cd Model-Pipeline
          timeout 300 python bias_detection.py || echo "[WARNING] Timeout"
          
          if [ -f "results/bias_report.json" ]; then
            VIOLATIONS=$(python -c "import json; data=json.load(open('results/bias_report.json')); print(len(data['violations']))")
            echo "violations=$VIOLATIONS" >> $GITHUB_OUTPUT
            echo "passed=true" >> $GITHUB_OUTPUT
          else
            echo "violations=0" >> $GITHUB_OUTPUT
            echo "passed=true" >> $GITHUB_OUTPUT
          fi

  rollback-check:
    name: Rollback Check
    runs-on: ubuntu-latest
    needs: [model-validation, bias-detection]
    if: needs.model-validation.outputs.validation-passed == 'true'
    outputs:
      deploy-approved: ${{ steps.compare.outputs.approved }}
      
    steps:
      - name: Compare models
        id: compare
        run: |
          NEW_F1=${{ needs.model-validation.outputs.f1-score }}
          PREV_F1=0.60
          
          IMPROVED=$(python -c "print($NEW_F1 > $PREV_F1)")
          if [ "$IMPROVED" = "True" ]; then
            echo "approved=true" >> $GITHUB_OUTPUT
            echo "[OK] Model improved: $NEW_F1 > $PREV_F1"
          else
            echo "approved=false" >> $GITHUB_OUTPUT
            echo "[WARNING] Rollback: $NEW_F1 <= $PREV_F1"
          fi

  deploy-model:
    name: Deploy to GCP
    runs-on: ubuntu-latest
    needs: [model-validation, bias-detection, rollback-check]
    if: |
      needs.model-validation.outputs.validation-passed == 'true' &&
      needs.rollback-check.outputs.deploy-approved == 'true' &&
      github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Authenticate to GCP
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
      
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v1
      
      - name: Download models
        uses: actions/download-artifact@v3
        with:
          name: trained-models
          path: Model-Pipeline/
      
      - name: Package model
        run: |
          cd Model-Pipeline/models
          tar -czf model-${{ github.sha }}.tar.gz best_model.pkl tfidf_vectorizer.pkl
      
      - name: Upload to Artifact Registry
        run: |
          VERSION=$(date +%Y%m%d-%H%M%S)-${{ github.sha }}
          
          gcloud artifacts repositories create echoai-models \
            --repository-format=generic \
            --location=${{ env.GCP_REGION }} \
            --project=${{ env.PROJECT_ID }} || true
          
          gcloud artifacts generic upload \
            --project=${{ env.PROJECT_ID }} \
            --location=${{ env.GCP_REGION }} \
            --repository=echoai-models \
            --package=sentiment-model \
            --version=$VERSION \
            --source=Model-Pipeline/models/model-${{ github.sha }}.tar.gz

  notify:
    name: Notifications
    runs-on: ubuntu-latest
    needs: [data-pipeline, model-training, model-validation, bias-detection, rollback-check, deploy-model]
    if: always()
    
    steps:
      - name: Pipeline status
        run: |
          echo "## Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "- Data Pipeline: ${{ needs.data-pipeline.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Model Training: ${{ needs.model-training.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Validation: ${{ needs.model-validation.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Bias Check: ${{ needs.bias-detection.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Deployment: ${{ needs.deploy-model.result }}" >> $GITHUB_STEP_SUMMARY